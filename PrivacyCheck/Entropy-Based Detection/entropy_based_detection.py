# -*- coding: utf-8 -*-
"""Entropy Based Detection.ipynb

Automatically generated by Colaboratory.

"""

!pip install simanneal

import json
import os
import random

import numpy as np
import scipy.stats as stats
import scipy.signal as signal
import matplotlib.pyplot as plt
from simanneal import Annealer

# Sliding window class to handle data being passed in one value at a time 
# This is based on number of data points, not time
class SlidingWindow:
  def __init__(self, size):
    assert size > 0
    self.size = size
    self.data = np.array([])
  def push(self, val):
    if len(self.data) < self.size:
      self.data = np.append(self.data, [val])
    else:
      self.data = np.append(self.data[1:], [val])

def calculate_shannon_entropy(data, precision=2):
  #sort continuous data into discrete buckets so entropy doesn't grow unbounded
  truncated_data = (data.round(decimals=precision) * (10 ** precision)).astype(int)
  value,counts = np.unique(truncated_data, return_counts=True)
  return stats.entropy(counts, base=2)

def get_data(filename):
  with open(filename) as data_file:
    data = np.array(json.load(data_file)['series'][0]['raw'])
    return data

def get_sliding_window_entropies(data, window_size):
  window = SlidingWindow(window_size)
  entropies = []
  for datum in data:
    window.push(datum)
    entropy = calculate_shannon_entropy(window.data)
    entropies.append(entropy)
  return entropies

def plot_entropy(filename, window_size=100):
  data = get_data(filename)
  calculate_shannon_entropy(data)
  entropies = get_sliding_window_entropies(data, window_size)
  plt.plot(entropies)
  plt.xlabel("Timestep")
  plt.ylabel("Shannon Entropy (bits)")
  print(filename.split("/")[-1])
  print("\tMin: ", min(entropies[2 * window_size:]))
  print("\tMax: ", max(entropies[window_size:]))

def plot_entropy_change(filename, window_size):
  data = get_data(filename)
  calculate_shannon_entropy(data)
  entropies = get_sliding_window_entropies(data, window_size)
  entropy_change = [entropies[i] - entropies[i - 1] for i in range(1, len(entropies))]  
  plt.plot(entropy_change)

def get_correct_changepoints(filepath):
  with open("/content/drive/MyDrive/School Work/Junior Year/Research/Input files/correct_changepoints.json") as file:
    correct_changepoints = json.load(file)
    filename = os.path.basename(filepath)
    assert filename in correct_changepoints
    return correct_changepoints[filename]

#REQUIRES: data starts off as normal, first changepoint marks anomalous
def get_data_labels(changepoints, length):
  is_anomaly = False
  tagged_data = np.zeros(length, dtype=bool)
  for i in range(length):
    if i in changepoints:
      is_anomaly = not is_anomaly
    tagged_data[i] = is_anomaly
  return tagged_data

def run_anomaly_detection(data, tagged_data, k, mu_e, sigma_e, window_size):

  # Main loop
  window = SlidingWindow(window_size)
  d_a = 0
  t_a = np.count_nonzero(tagged_data)
  d_n = 0
  t_n =  len(data) - np.count_nonzero(tagged_data)

  for i in range(len(data)):
    #calculate sliding window entropy for this time step
    datum = data[i]
    window.push(datum)
    entropy = calculate_shannon_entropy(window.data)
    
    # see if this is anomalous
    if (entropy < (mu_e - k * sigma_e)) or (entropy > (mu_e + k * sigma_e)):
      #we think data is anomalou
      if tagged_data[i] == True:
        #increment d_a if we are correct and data was anomalous and flagged as such
        d_a += 1
      else:
        #increment d_n if we are wrong and data was normal but flagged as anomalous
        d_n += 1
  
  r_a = (d_a / t_a) * 100
  r_n = (d_n / t_n) * 100

  return r_a, r_n

def generate_average_pure_entropies():
  # pure_data = get_data("/content/drive/MyDrive/School Work/Junior Year/Research/Input files/driver_scores_pure.json")
  # average_entropies_by_windowsize = [np.average(get_sliding_window_entropies(pure_data, window_size)[window_size:]) for window_size in range(10,201)]
  # return(average_entropies_by_windowsize)
  #CACHED RESULT:
  return [3.295093924033091, 3.429905589111268, 3.552685505415992, 3.665365582412704, 3.7696625037005327, 3.866521158160995, 3.956842237903226, 4.04172109523272, 4.121467918599445, 4.19666393643558, 4.267982017551339, 4.335698650671426, 4.400240184739172, 4.461840654018066, 4.520816939401629, 4.577298138888167, 4.631299190804364, 4.683200597702566, 4.733117422962354, 4.781223836805177, 4.827742929363912, 4.872807497700515, 4.916346601878982, 4.958392962966228, 4.999097606897485, 5.038498498223179, 5.076680986604404, 5.113729786680426, 5.149742609477156, 5.1846942057131225, 5.218588521224829, 5.251595108987465, 5.283649795460152, 5.3149834853150395, 5.345478931245242, 5.375206116219083, 5.404265840366247, 5.432620401064088, 5.460270358844343, 5.487271602472325, 5.513653297463482, 5.539412430117489, 5.564573803021948, 5.5891486910330315, 5.613190619189123, 5.636733412398151, 5.659806403947477, 5.6824191373728805, 5.704647440352809, 5.726485935907786, 5.747927542874964, 5.769021037960023, 5.789693621688283, 5.809963113010669, 5.829919208916913, 5.849507204991052, 5.868748178296186, 5.887619581111784, 5.906149971787375, 5.924355095696765, 5.94226278571856, 5.959881285559818, 5.977200558555168, 5.994271546699901, 6.011039104336407, 6.027594756545891, 6.043934894231956, 6.0599835337646315, 6.0758419362590335, 6.091372519410968, 6.1066934833027435, 6.121787116787945, 6.1366685103019245, 6.1513850771404, 6.165952578781832, 6.180321673798129, 6.1944633713675135, 6.2084626868949275, 6.222286607374241, 6.235916894297208, 6.249349068026935, 6.262613410941519, 6.275720498305209, 6.288697532116012, 6.301520303640035, 6.314184999734712, 6.326694799823926, 6.339048697248334, 6.351235021205925, 6.363318369060211, 6.375218704031534, 6.387014911370867, 6.3987015546909145, 6.410258610524039, 6.421702405004445, 6.433041108787515, 6.444262697521548, 6.455343296563521, 6.466275764861204, 6.477062927457946, 6.48771351626833, 6.498243181375968, 6.5086918654250345, 6.51901023943914, 6.5292227543834525, 6.539336883604364, 6.549370234007401, 6.5592700315771655, 6.569090490920519, 6.578836527229816, 6.588498087467698, 6.598037887681449, 6.607496221797393, 6.616861167105704, 6.62613728501994, 6.6353356720429915, 6.644451010626817, 6.65347926134663, 6.662411839380395, 6.671250626465299, 6.6800043461637975, 6.688660979858186, 6.697233697835133, 6.705719095751274, 6.714150444863991, 6.7224886152720105, 6.73075077809167, 6.738965475776904, 6.74709997850291, 6.755162267771014, 6.763155187709501, 6.7710796430624836, 6.778951681330457, 6.78676619220071, 6.794509874893805, 6.80219754696827, 6.8098438007355195, 6.817418669846389, 6.824923091452009, 6.832335268927818, 6.839688068427271, 6.8469947725696105, 6.854231804427498, 6.861435447397306, 6.868554976799189, 6.875595895851554, 6.882577486044531, 6.889504757671951, 6.896390389563275, 6.903207452007621, 6.909974624217208, 6.9167008595877, 6.923351318656362, 6.929967054745011, 6.936540836087069, 6.943069835421562, 6.9495479415896515, 6.955972382262322, 6.9623535710619855, 6.968687918090752, 6.974990348362714, 6.981246758925382, 6.987422580440551, 6.993551309802497, 6.9996385882593675, 7.005695214211602, 7.011709871871262, 7.017672918191631, 7.0236095810909065, 7.029489359747271, 7.035338808376005, 7.041155188336025, 7.046927373130279, 7.052650967554301, 7.058336608671158, 7.063973408811781, 7.069570828280988, 7.075112989042887, 7.08061367264465, 7.086074054746589, 7.09150977242064, 7.09690581018795, 7.10227276712127, 7.107588466899498, 7.112872723963509, 7.1180981401847685, 7.123301423981192, 7.1284763340236115, 7.133612621007234, 7.138714116741451, 7.143797793875064]

def entropy_anomaly_detection(filename, k, sigma_e, window_size, mu_e=6.35):
  data = get_data(filename)
  correct_changepoints = get_correct_changepoints(filename)
  labeled_data = get_data_labels(correct_changepoints, len(data))
  return(run_anomaly_detection(data, labeled_data, k, mu_e, sigma_e, window_size))

class EntropyBasedDetectionAnnealer(Annealer):
  """Simulated annealing to tune EBD params"""
  def __init__(self, state, filename):
    self.data = get_data(filename)
    self.pure_entropies = generate_average_pure_entropies()
    changepoints = get_correct_changepoints(filename)
    self.tagged_data = get_data_labels(changepoints, len(self.data))
    super(EntropyBasedDetectionAnnealer, self).__init__(state)

  def clamp(self, x, lower, upper):
    return max(lower, min(upper, x))

  def move(self):
    # move to nearby neighbor
    #find random sigma
    sigma_change = 2 * (random.random() - 0.5)
    new_sigma = self.state['sigma_e'] + sigma_change
    self.state['sigma_e'] = self.clamp(new_sigma, 0.1, 10)

    # find random size
    if self.state['window_size'] >= 10 and self.state['window_size'] < 200:
      new_window = random.randint(self.state['window_size']-10,self.state['window_size'] + 10)
    elif self.state['window_size'] < 10:
      new_window = random.randint(0, 20)
    else:
      new_window = random.randint(180,200)
    self.state['window_size'] = self.clamp(new_window, 10, 200)

    # update mean based on selected windowsize
    self.state['mu_e'] = self.pure_entropies[self.state['window_size'] - 10]


  def energy(self):
    # get energy of this state. goal is to minimize, so we take negative of paper algorithm
    c1 = 1
    c2 = 1
    #offset indexing because get pure entropies returns slice from 10 to 200
    r_a, r_n = run_anomaly_detection(self.data, self.tagged_data, self.state['k'], self.state['mu_e'], self.state['sigma_e'], self.state['window_size'])
    return (c2 * r_n - c1 * r_a)



initial_params = {'mu_e': 6.35, 'sigma_e': 3.42, 'k': 1, 'window_size': 100}
filename = "/content/drive/MyDrive/School Work/Junior Year/Research/Input files/driver_scores_every80.json"
print("Initializing annealer...")
annealer = EntropyBasedDetectionAnnealer(initial_params, filename)
print("Annealer initialized.")

annealer.Tmax = 25000
annealer.Tmin = 2.5
annealer.steps = 25000
annealer.updates=0

# auto_params = annealer.auto(minutes=1)
# print("autogenerated params: ", auto_params)
# annealer.set_schedule(auto_params)
print("Running annealing...")
state, e = annealer.anneal()
print("Annealing finished!")
print(f"Final state: {state}")

print(state)

result = entropy_anomaly_detection(filename, state['k'], state['mu_e'], state['sigma_e'], state['window_size'])
print(result)
print(result[0] - result[1])

"""Big: {'mu_e': 6.35, 'sigma_e': 3.1043850104225093, 'k': 1, 'window_size': 12}

Bigger: {'mu_e': 6.35, 'sigma_e': 3.4278004574389627, 'k': 1, 'window_size': 10} - (97.70992366412213, 1.5650741350906094)

"""

average_pure_entropies = generate_average_pure_entropies()
def run_murali_anomaly_detection(data, tagged_data, cutoff, window_size):
  # Main loop
  window = SlidingWindow(window_size)
  d_a = 0
  t_a = np.count_nonzero(tagged_data)
  d_n = 0
  t_n =  len(data) - np.count_nonzero(tagged_data)

  for i in range(len(data)):
    #calculate sliding window entropy for this time step
    datum = data[i]
    window.push(datum)
    entropy = calculate_shannon_entropy(window.data)
    
    # see if this is anomalous
    if entropy < cutoff:
      #we think data is anomalous
      if tagged_data[i] == True:
        #increment d_a if we are correct and data was anomalous and flagged as such
        d_a += 1
      else:
        #increment d_n if we are wrong and data was normal but flagged as anomalous
        d_n += 1
  
  r_a = (d_a / t_a) * 100
  r_n = (d_n / t_n) * 100

  return r_a, r_n 
  


def energy(data, tagged_data, cutoff, window_size):
    # get energy of this state. goal is to minimize, so we take negative of paper algorithm
    r_a, r_n = run_murali_anomaly_detection(data, tagged_data, cutoff,  window_size)
    return r_a - r_n

# order is cutoff, windowsize
filename = "/content/drive/MyDrive/School Work/Junior Year/Research/Input files/driver_scores_every80.json"
data = get_data(filename)
changepoints = get_correct_changepoints(filename)
tagged_data = get_data_labels(changepoints, len(data))

coords_map = [(i, j) for i in np.linspace(2, 6, 151) for j in range(10, 100)]
len(coords_map)

fitness = [energy(data, tagged_data, cutoff, w) for cutoff, w in coords_map]
print(fitness)

plot_entropy(filename, 74)

"""sigma = 0.5, w = 11 has best performance of -75.4"""
# -*- coding: utf-8 -*-
"""Driver_score_Adaboost_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GlCa825uloVFwwKTBfd2SSNj78_-BAGT
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import math

driving_data = pd.read_csv(r'driver_score_data.csv',
                           usecols=['AccelPedal', 'Guess Engine_speed', 'Speed', 'Time',
                                    'Device id'])

'also guess column S to be calculated LOAD for now'
calculated_load = pd.read_csv(r'driver_score_data.csv', usecols=['Guess Engine_speed'])
calculated_load = calculated_load.rename(columns={'Guess Engine_speed': 'Calculated_LOAD_value'})

driving_data = driving_data.join(calculated_load)

driving_data = driving_data.rename(
    columns={'Guess Engine_speed': 'Engine_speed', 'AccelPedal': 'Absolute_throttle_position', 'Speed': 'Vehicle_speed',
             'Time': 'Time(s)'})

# calculate the driving score for each driver
drivers = {}
for i, g in driving_data.groupby('Device id'):
    # print 'data_' + str(i)
    # print g
    drivers.update({int(i): g.reset_index(drop=True)})

driver_scores = {}

for driver, data in drivers.items():
    data = data.drop(columns=['Device id'])

    # Check for any missing values
    # data.isnull().values.any()

    # plt.style.use('ggplot')
    # pd.plotting.scatter_matrix(driver_A, alpha=0.3, figsize=[10, 10], s=50)

    # Seaborn scatter matrix
    # g = sns.PairGrid(driver_A)
    # g = g.map(plt.scatter)

    # driver_A.corr(method='pearson').style.format("{:.2}").background_gradient(cmap=plt.get_cmap('coolwarm'), axis=1)

    # driver_A.isnull().values.any()
    throttle_change_rate = np.diff(data['Absolute_throttle_position'].values)
    throttle_change_rate = np.append(throttle_change_rate, data.tail(1).Absolute_throttle_position.values)
    es_change_rate = np.diff(data['Engine_speed'].values)
    es_change_rate = np.append(es_change_rate, data.tail(1).Engine_speed.values)
    vs_change_rate = np.diff(data['Vehicle_speed'].values)
    vs_change_rate = np.append(vs_change_rate, data.tail(1).Vehicle_speed.values)

    mod_relative_A = pd.DataFrame({'Throttle_change_rate': throttle_change_rate, 'ES_change_rate': es_change_rate,
                                   'VS_change_rate': vs_change_rate, 'Engine_load': data.Calculated_LOAD_value.values})

    # mod_relative_A.describe()

    # g = sns.PairGrid(mod_relative_A)
    # g = g.map_diag(plt.hist)
    # g = g.map_offdiag(plt.scatter)

    # mod_relative_A.isnull().any()

    # mod_relative_A.head()

    vehicle_speed_norm = [x / 220 for x in data['Vehicle_speed'].values]
    engine_speed_norm = [x / 8000 for x in data['Engine_speed'].values]

    rr_of_vs_and_es = [i / j for i, j in zip(vehicle_speed_norm, engine_speed_norm)]
    # len(rr_of_vs_and_es)

    maximum_change_tp = max(mod_relative_A['Throttle_change_rate'].values)
    maximum_change_es = max(mod_relative_A['ES_change_rate'].values)
    throttle_position_norm = [x / maximum_change_tp for x in mod_relative_A['Throttle_change_rate'].values]
    # len(throttle_position_norm)
    es_relative_norm = [x / maximum_change_es for x in mod_relative_A['ES_change_rate'].values]
    # len(es_relative_norm)
    rr_of_tp_and_es = pd.Series([i / j for i, j in zip(throttle_position_norm, es_relative_norm)])
    # len(rr_of_tp_and_es)
    # np.isneginf(rr_of_tp_and_es).any()

    rr_of_tp_and_es.replace([np.inf, -np.inf], np.nan)
    # rr_of_tp_and_es.describe()

    # np.isinf(rr_of_tp_and_es).any()

    feature_set = pd.DataFrame({'rr_of_vs_and_es': rr_of_vs_and_es, 'rr_of_tp_and_es': rr_of_tp_and_es,
                                        'engine_load': mod_relative_A['Engine_load'].values})

    # feature_set.describe()

    feature_set = feature_set[~feature_set.isin([np.nan, np.inf, -np.inf]).any(1)]
    # feature_set.tail()

    labels = []
    for index, row in feature_set.iterrows():
        # if (0.9 <= row['rr_of_vs_and_es']<= 1.3) and (0.9 <= row['rr_of_tp_and_es']<=1.3) and (20 <= row['engine_load'] <= 50):
        'standard modified to accomadate current dataset'
        if (2 <= row['rr_of_vs_and_es'] <= 13) and (2 <= row['rr_of_tp_and_es'] <= 13) and (0 <= row['engine_load'] <= 30):

            labels.append(1)
        else:
            labels.append(-1)
    driver_scores[driver] = labels

final_scores = {}
for driver, labels in driver_scores.items():
    final_score = pd.Series(labels).dropna().mean()
    if math.isnan(final_score):
        continue
    final_scores[driver] = final_score

print(final_scores)
with open('scores.txt', 'w') as scores_file:
    for d, s in final_scores.items():
        print(s, file=scores_file)

# pd.Series(labels).describe()

"""Finished Assigning Driver Scores!"""

# feature_set_driverA['label'] = labels

"""**Don't Need to do Adaboost classifying**"""

# data = feature_set_driverA[['rr_of_vs_and_es', 'rr_of_tp_and_es', 'engine_load']]
# target = feature_set_driverA['label']

# from sklearn.ensemble import AdaBoostClassifier
# from sklearn.model_selection import train_test_split
# from sklearn import metrics

# X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3)

# adaboost_classifier = AdaBoostClassifier(n_estimators=50, learning_rate=1)
# Train Adaboost Classifer
# decision_tree_model = adaboost_classifier.fit(X_train, y_train)

# Predict the response for test dataset
# y_pred = decision_tree_model.predict(X_test)

# Model Accuracy, how often is the classifier correct?
# print("Accuracy:", metrics.accuracy_score(y_test, y_pred))
